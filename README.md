# 🧠 Parallel Log File Analyzer for Distributed Systems

## 📍 Overview
This project implements a **Parallel Log File Analyzer** using **C++** and **OpenMP** to efficiently process and analyze large log files generated by distributed systems.  
It provides **serial and parallel implementations**, measures **performance speedup**, and analyzes **system logs** to extract valuable insights.

---

## 🎯 Objectives`
- Efficiently process large log files generated by servers or distributed systems.  
- Extract meaningful insights:
  - Frequency of important keywords (`ERROR`, `WARNING`, `INFO`, `DEBUG`)
  - Most frequent IPs/users
  - Trends of errors across time windows
- Compare **serial vs. parallel** performance using OpenMP.

---

## ⚙️ Features
✅ Supports **multiple log files**  
✅ Counts keyword   frequencies  
✅ Detects **top N frequent IPs**  
✅ Identifies **top N recurring error messages**  
✅ Tracks **error trends over time**  
✅ Benchmarks and compares **serial vs. parallel performance**

---

## 📂 Project Structure

```
📁 Project Root
├── 📁 bin/                    # Compiled executables
│   ├── benchmark             # Performance comparison tool
│   ├── main                  # Interactive mode selector
│   ├── parallel_analyzer     # Parallel analysis executable
│   ├── serial_analyzer       # Serial analysis executable
│   └── run_benchmark         # Comprehensive benchmark tool
├── 📁 data/                  # Sample log files
│   ├── log1.txt, log2.txt   # Sample log files
│   └── log_generator.py     # Generates test log files
├── 📁 include/               # Header files
│   ├── analyzer_utils.h     # Core analysis logic & data structures
│   ├── log_parser.h         # File reading utilities
│   └── timer.h              # Performance timing utilities
├── 📁 scripts/               # Python visualization scripts
│   ├── plot_performance.py  # Serial vs Parallel comparison
│   ├── plot_speedup.py      # Speedup analysis
│   ├── plot_efficiency.py   # Efficiency analysis
│   └── run_all_benchmarks.py # Master automation script
├── 📁 results/               # Performance reports & graphs
│   ├── benchmark_data.csv   # Raw benchmark data
│   └── *.png                # Generated visualization graphs
├── 📁 src/                   # Source code files
│   ├── benchmark.cpp        # Benchmark comparison
│   ├── main.cpp             # Interactive mode
│   ├── parallel_analyzer.cpp # Parallel implementation
│   ├── serial_analyzer.cpp  # Serial implementation
│   └── run_benchmark.cpp    # Comprehensive benchmark
├── ALGORITHM_PSEUDOCODE.md  # Algorithm documentation
├── BENCHMARK_GUIDE.md       # Benchmarking guide
├── documentation.md         # Detailed documentation
├── MAKEFILE                  # Build configuration
└── README.md                 # This file
```

---

## 🔧 Technical Implementation

### Core Components

**LogStats Structure** - Stores analysis results (keyword counts, IP frequencies, error messages)  
**Serial Analysis** - Sequential processing with O(n) time complexity  
**Parallel Analysis** - OpenMP-based parallel processing with 4 threads by default  
**Timer** - High-resolution performance measurement using `omp_get_wtime()`  
**File I/O** - Efficient multi-file reading with vector-based storage

### Key Features
- **OpenMP Parallelization**: Uses `#pragma omp parallel for` with reduction operations
- **Thread Safety**: Critical sections for HashMap updates, reduction for counters
- **Performance**: Achieves 3-4x speedup on 4-core systems for large datasets
- **Analysis**: Extracts top IPs, error messages, and keyword frequencies

See `ALGORITHM_PSEUDOCODE.md` for detailed algorithm documentation.

---

## 🚀 Quick Start

### Prerequisites
- **Compiler**: GCC with OpenMP support (`-fopenmp`)
- **Python 3** (for visualization scripts): `pip install pandas matplotlib numpy`

### Build & Run

```bash
# Build all executables
make all

# Run interactive mode (choose serial or parallel)
make run-main

# Or run directly
make run-serial      # Serial analysis
make run-parallel    # Parallel analysis
make run-bench       # Performance comparison
```

### Generate Log Files & Run Complete Benchmark

```bash
# Generate test log files of different sizes
python3 data/log_generator.py

# Run complete benchmark suite and generate graphs
python3 scripts/run_all_benchmarks.py
```

This will generate:
- `results/benchmark_data.csv` - Raw performance data
- `results/serial_vs_parallel.png` - Performance comparison
- `results/speedup_analysis.png` - Speedup analysis
- `results/efficiency_analysis.png` - Efficiency analysis

---

## 📊 Performance & Benchmarking

### Expected Performance
- **Small Files** (< 1MB): Minimal speedup due to overhead
- **Medium Files** (1-100MB): 2-3x speedup on 4-core systems
- **Large Files** (> 100MB): 3-4x speedup on 4-core systems

### Benchmarking
The project includes comprehensive benchmarking tools:
- **CSV Data Export**: Raw performance metrics saved to `results/benchmark_data.csv`
- **Visualization Scripts**: Generate performance, speedup, and efficiency graphs
- **Multi-size Testing**: Test with log files ranging from 100 to 100,000 lines

See `BENCHMARK_GUIDE.md` for detailed benchmarking instructions.

---

## 🔍 Sample Output

```
=== Keyword Frequency ===
INFO    : 3
ERROR   : 4
WARNING : 2
DEBUG   : 1

=== Top IPs ===
192.168.0.2 -> 2 times
192.168.0.7 -> 2 times
192.168.0.1 -> 1 times

=== Top Error Messages ===
"Database connection failed" -> 1 times
"Timeout occurred" -> 1 times

Execution Time: 0.001234 seconds
```

## 📄 Documentation

- **ALGORITHM_PSEUDOCODE.md** - Detailed algorithm and parallelization strategy
- **BENCHMARK_GUIDE.md** - Complete benchmarking and visualization guide
- **documentation.md** - Comprehensive project documentation

---

## 📚 Additional Resources

- [OpenMP Documentation](https://www.openmp.org/)
- [C++17 Reference](https://en.cppreference.com/)
- See `scripts/README.md` for Python visualization tools

## 📝 License

Developed for educational purposes as part of the Parallel and Distributed Computing course at IIIT Kottayam.

**Course**: PDC | **Semester**: 5 | **Academic Year**: 2024-25